"""
Advanced Deep Research with Agentic AI capabilities
LangChain implementation with OpenRouter integration
"""
import os
from typing import Dict, Any, TypedDict, List
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langsmith import Client
from research_agents import ResearchAgents
import asyncio
import sys
from datetime import datetime
import logging

# Initialize environment variables
print("Loading environment variables...")
load_dotenv()

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Verify OpenRouter API key
if not os.getenv("OPENROUTER_API_KEY"):
    raise ValueError("OPENROUTER_API_KEY environment variable is not set")

# Initialize LangSmith client if API key is available
client = None
if os.getenv("LANGSMITH_API_KEY"):
    print("Initializing LangSmith client...")
    client = Client()

class ResearchState(TypedDict):
    query: str
    research_data: List[str]
    analysis: str

async def create_research_workflow() -> ResearchAgents:
    print("Creating research workflow...")
    try:
        # Initialize the language model with OpenRouter
        llm = ChatOpenAI(
            model="openai/o3-mini",
            temperature=0.7,
            api_key=os.getenv("OPENROUTER_API_KEY"),
            base_url="https://openrouter.ai/api/v1",
            default_headers={
                "HTTP-Referer": "https://research-project.com",
                "X-Title": "Advanced Deep Research"
            }
        )
        print("LLM initialized successfully with OpenRouter")
        
        # Initialize research agents
        research_agents = ResearchAgents(llm)
        print("Research agents initialized")
        
        return research_agents
        
    except Exception as e:
        print(f"Error in create_research_workflow: {str(e)}", file=sys.stderr)
        raise

async def process_research(query: str) -> None:
    print("Processing research...")
    research_agents = await create_research_workflow()
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    try:
        # Execute research phase
        print("\nExecuting research phase...")
        research_result = await research_agents.research(query)
        print("\nResearch Results:")
        print("----------------")
        print(research_result)
        
        # Execute analysis phase
        print("\nExecuting analysis phase...")
        analysis_result = await research_agents.analyze(research_result)
        print("\nAnalysis:")
        print("---------")
        print(analysis_result)
        
        # Generate markdown report with improved structure
        report_md = f"""# Research Report: Quantum Computing and Cryptography
*Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*

## Table of Contents
- [Research Query](#research-query)
- [Research Results](#research-results)
- [Analysis](#analysis)
  - [Key Findings](#key-findings)
  - [Emerging Trends](#emerging-trends)
  - [Technical Implications](#technical-implications)
  - [Business Impact](#business-impact)
  - [Future Outlook](#future-outlook)
  - [Recommendations](#recommendations)
- [Metadata](#metadata)

## Research Query
```
{query}
```

## Research Results
{research_result}

## Analysis
{analysis_result}

## Metadata
- **Research Sources**: See citations in research results

---
*Report generated by Advanced Deep Research with Agentic AI capabilities*
"""
        
        # Save markdown report
        os.makedirs('reports', exist_ok=True)
        report_file = f'reports/research_report_{timestamp}.md'
        with open(report_file, "w", encoding="utf-8") as f:
            f.write(report_md)
        print(f"\nMarkdown report saved to {report_file}")
        
        # Save agent reasoning chain separately
        reasoning_chain = research_agents.get_agent_chain()
        reasoning_file = f'reports/agent_reasoning_{timestamp}.md'
        with open(reasoning_file, "w", encoding="utf-8") as f:
            f.write("# Agent Reasoning Chain\n\n")
            f.write(reasoning_chain)
        print(f"\nAgent reasoning chain saved to {reasoning_file}")
        
        # Also save raw results for backward compatibility
        with open("research_report.txt", "w", encoding="utf-8") as f:
            f.write("Research Query:\n")
            f.write("--------------\n")
            f.write(query + "\n\n")
            f.write("Research Results:\n")
            f.write("----------------\n")
            f.write(str(research_result) + "\n\n")
            f.write("Analysis:\n")
            f.write("---------\n")
            f.write(str(analysis_result) + "\n\n")
        print("\nRaw results saved to research_report.txt")
        
    except Exception as e:
        error_msg = f"\nResearch failed: {str(e)}"
        logger.error(error_msg)
        if client:
            logger.info("Logging error to LangSmith...")
            try:
                client.log_feedback(
                    run_id=client.run_id,
                    key="error",
                    value=error_msg
                )
                logger.info("Logged error to LangSmith successfully")
            except Exception as feedback_error:
                logger.error(f"Failed to log error: {str(feedback_error)}")

async def main():
    print("Running main...")
    # Example research query
    query = "What are the latest developments in quantum computing and its potential impact on cryptography?"
    await process_research(query)
    print("Main completed successfully")

if __name__ == "__main__":
    try:
        print("Running asyncio main...")
        asyncio.run(main())
        print("Asyncio main completed successfully")
    except Exception as e:
        print(f"Error in main: {str(e)}", file=sys.stderr)
        import traceback
        print(traceback.format_exc())
